{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Segmentation\n",
    "\n",
    "In the final step, we will perform the segmentation and wear measurement. Your task will be to receive unseen images for the model, perform segmentation on these images, and finally measure the wear thickness to plot the corresponding VB curve for each cutting edge.\n",
    "\n",
    "For having a better results in segmentation, you will receive a weight that has been trained on a larger dataset, resulting in improved accuracy. However, before proceeding with the segmentation task, certain preprocessing steps are required to ensure optimal results.\n",
    "\n",
    "If you have any doubts about the previous section, please go ahead and book a consultation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(r\"KIP.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1. Image Alignment\n",
    "Before delving into segmentation, it's essential to address potential issues stemming from image acquisition, such as image shifting. To mitigate these issues and ensure consistency across images, we will employ image alignment techniques.\n",
    "\n",
    "By aligning the images based on a reference or source image, we can ensure that the cutting edge, or the region of interest, remains roughly in the same position across all images. This not only simplifies the segmentation process but also improves the accuracy of subsequent measurements, such as wear thickness calculation.\n",
    "\n",
    "With the images properly aligned, we can proceed confidently to the segmentation phase, where we'll extract meaningful insights regarding wear thickness and plot the corresponding VB curve.\n",
    "\n",
    "You can find the images and the weight here: https://bwsyncandshare.kit.edu/s/kpdaZs6EtcM5Bpn\n",
    "\n",
    "The test dataset comprises a complete set of cutting-edge images, starting from the beginning to the end of the tool's lifespan (approximately 200Î¼m). As the tool has four cutting edges, four images are captured after each data collection step. The collection step occurs after every 10 tests, meaning the milling process is performed 10 times then four images are taken. This sequence is then repeated.\n",
    "\n",
    "***Please refresh the images folder to view the images in the notebook (Download the updated images from ilias)\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/image-14.png\" alt=\"Alt text\" style=\"display: block; margin: 0 auto;\">\n",
    "</div>\n",
    "'\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/image-15.png\" alt=\"Alt text\" style=\"display: block; margin: 0 auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TASK: Try using the OpenCV library to implement the alignment method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import os \n",
    "import numpy as np \n",
    "\n",
    "###Import folder contains images for Image Alignment\n",
    "int_folder = \"Input Directory\"\n",
    "\n",
    "# Get the list of image files and skip the first one\n",
    "image_files = [filename for filename in os.listdir(int_folder) if filename.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "image_files_source = image_files[0]\n",
    "image_files_test = image_files[1:]\n",
    "\n",
    "for filename in image_files_source: \n",
    "    # Open the image\n",
    "    img_path = os.path.join(int_folder, filename)\n",
    "    imgRef = cv2.imread(img_path)\n",
    "    imgRef_grey = cv2.cvtColor(imgRef, cv2.COLOR_BGR2GRAY) \n",
    "    sz = imgRef_grey.shape \n",
    "\n",
    "# Define the motion model \n",
    "warp_mode = cv2.MOTION_TRANSLATION \n",
    "\n",
    "# Define 2x3 matrices and initialize the matrix to identity \n",
    "warp_matrix = np.eye(2, 3, dtype=np.float32) \n",
    "\n",
    "# Specify the number of iterations. \n",
    "number_of_iterations = 10000; \n",
    "\n",
    "# Specify the threshold of the increment \n",
    "# in the correlation coefficient between two iterations \n",
    "termination_eps = 1e-10; \n",
    "\n",
    "# Define termination criteria \n",
    "criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, number_of_iterations,  termination_eps)  \n",
    "\n",
    "\n",
    "for filename in image_files_test: \n",
    "    # Open the image\n",
    "    img_path = os.path.join(int_folder, filename)\n",
    "    imgTest = cv2.imread(img_path)   \n",
    "    # Convert to grayscale. \n",
    "    imgTest_grey = cv2.cvtColor(imgTest, cv2.COLOR_BGR2GRAY) \n",
    "    (cc, warp_matrix) = cv2.findTransformECC (imgRef_grey,imgTest_grey,warp_matrix, warp_mode, criteria) \n",
    "    aligned_img = cv2.warpAffine(imgTest, warp_matrix, (sz[1],sz[0]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP) \n",
    "    # Save the aligned image\n",
    "    ALIGN = f'{filename[:-4]}_aligned.jpg'\n",
    "    cv2.imwrite(ALIGN, aligned_img)\n",
    "    \n",
    "    # Detect ORB keypoints and descriptors\n",
    "    orb = cv2.ORB_create(MAX_FEATURES)\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(imgRef_grey, None)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2. ROI Extraction\n",
    "\n",
    "In our data preprocessing step, we have already identified the regions of interest (ROI) within the original images. Now, our task is to crop these ROIs from the test dataset as well. This is crucial for reducing the size of the images, which can streamline subsequent processing steps and improve computational efficiency.\n",
    "\n",
    "By extracting only the relevant regions from the original images, we focus our computational resources on the areas that are most important for our analysis. This not only speeds up processing but also helps in maintaining the integrity of the data by minimizing irrelevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TASK: Crop the Region of Interest (ROI) area, as performed in the training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output directories\n",
    "int_folder = \"Input Directory\"\n",
    "out_folder = \"Output Directory\"\n",
    "\n",
    "for filename in os.listdir(int_folder): \n",
    "    if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "        # Open the image\n",
    "        img_path = os.path.join(int_folder, filename)\n",
    "        imgTest = cv2.imread(img_path)  \n",
    "        imgheight = imgTest.shape[0]\n",
    "        imgwidth = imgTest.shape[1]\n",
    "        cropped_image = imgTest[int(imgwidth/2)-1000:int(imgwidth/2)+1000, int(imgheight/2)-700:int(imgheight/2)+700] # Slicing to crop the image\n",
    "\n",
    "        # Output filename with \"_cropped\" added\n",
    "        output_filename = os.path.splitext(filename)[0] + \"_cropped.jpg\"\n",
    "\n",
    "        # Save the cropped image to the output directory\n",
    "        output_path = os.path.join(out_folder, output_filename)\n",
    "        cv2.imwrite(output_path, cropped_image)\n",
    "print(\"Cropping completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3. Image resizing\n",
    "\n",
    "In order to utilize the provided segmentation model effectively, you need to resize the images to a specific size, in this case, 512 x 512 pixels. Resizing images to a consistent dimension ensures compatibility with the model's input requirements and helps maintain the aspect ratio of the original images.\n",
    "\n",
    "* TASK: Implement the code to resize the images to the desired dimensions\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/image-17.png\" alt=\"Alt text\" style=\"display: block; margin: 0 auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TASK: Resize the images to match the dimensions of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output directories\n",
    "int_folder = \"Input Directory\"\n",
    "out_folder = \"Output Directory\"\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(('.jpg', '.jpeg', '.png')):  # Add other image formats if needed\n",
    "        # Open the image\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        im = Image.open(img_path)\n",
    "\n",
    "        # Resize the image to (512, 512)\n",
    "        im_resized = im.resize((512, 512))\n",
    "\n",
    "        # Save the resized image in TIFF format to the output folder\n",
    "        output_path = os.path.join(output_folder, os.path.splitext(filename)[0] + '.jpg')\n",
    "        im_resized.save(output_path, 'JPEG')\n",
    "\n",
    "print(\"Resizing completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4. Segmenattion Model Implemanation\n",
    "\n",
    "Now that we have completed all the preprocessing steps, our images are prepared for segmentation. By utilizing the provided weight, you can generate the segmentation results for these preprocessed images.\n",
    "\n",
    "ATTENTION: YOU NEED TO RESIZE THE SEGMENTATION RESULT TO THE ORIGINAL SIZE TO KEEP THE PIXEL RATIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TASK: Implement the segmentation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output directories\n",
    "int_folder = \"Input Directory\"\n",
    "out_folder = \"Output Directory\"\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith('.jpg'):  # Assuming you want to process TIFF images\n",
    "        # Get the input image path\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "\n",
    "        # Read and normalize the image\n",
    "        test_img_other = cv2.imread(img_path, 0)\n",
    "        test_img_other_norm = np.expand_dims(normalize(np.array(test_img_other), axis=1),2)\n",
    "\n",
    "\n",
    "        test_img_other_norm=test_img_other_norm[:,:,0][:,:,None]\n",
    "        test_img_other_input=np.expand_dims(test_img_other_norm, 0)\n",
    "\n",
    "        # Predict and threshold for values above 0.2 probability\n",
    "        prediction_other = (model.predict(test_img_other_input)[0, :, :, 0] > 0.2).astype(np.uint8)\n",
    "\n",
    "        # Resize the prediction back to the original cropped size\n",
    "        prediction_other_resized = cv2.resize(prediction_other, (cropped_image.shape[1], cropped_image.shape[0]))\n",
    "\n",
    "        # Save the prediction as an image\n",
    "        output_path = os.path.join(output_folder, f'{os.path.splitext(filename)[0]}_prediction.png')\n",
    "        Image.fromarray(prediction_other * 255).save(output_path)  # Save as PNG\n",
    "\n",
    "print(\"Prediction completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of the segmentation results obtained after applying the segmentation model.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/image-19.png\" alt=\"Alt text\" style=\"display: block; margin: 0 auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Wear Measurement\n",
    "In this step, we are going to find out the thickness of the wear area in each image, so we can see a trend of how the wear is changing by continuing the milling process. Of course, the segmentation results are not 100% perfect, but as we just need to focus on the maximum thickness in each image, we are on the safe side. At the end of this step, there will be a value for the maximum thickness for each image. The pixel ratio that we have in the image is 1.725 Î¼m per pixel. In this section, you have complete freedom to implement your own solution, however I will provide some hints to get you started. Let's dive into the last step :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1. label the Target Cluster\n",
    "\n",
    "If you check the results, you will probably see some misdetections where the model labeled areas as wear, which are not. To eliminate these artifacts and focus on the target wear area, you can implement a clustering method to identify the target area. Since the images are already aligned and the cutting edge coordinates are similar, you can also define a bounding box to locate the target cluster more accurately.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/image-20.png\" alt=\"Alt text\" style=\"display: block; margin: 0 auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TASK: Try to locate the right segmentation area. For this purpose, you can use findContours from OpenCV, but you can also implement your own solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contour_indices(contours):\n",
    "    valid_indices = []\n",
    "    for i in range(len(contours)):\n",
    "        if len(contours[i]) > 50:\n",
    "            for j in range(len(contours[i])):\n",
    "                if 450 < contours[i][j][0][0] + contours[i][j][0][1] < 550:\n",
    "                    valid_indices.append(i)\n",
    "                    break  # Exit the inner loop once condition is met for this contour\n",
    "    return valid_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2. VB Measuring\n",
    "\n",
    "In this step, we will measure the maximum thickness of the wear. You can implement a combination of functions from OpenCV, such as findContours and Canny edge detection, to find the thickness. It's important to calculate the orthogonal distance (line 1 in Max VB) each time, not the horizontal distance (line 2 in Max VB).\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/image-21.png\" alt=\"Alt text\" style=\"display: block; margin: 0 auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TASK: Try to measure the maximum wear thickness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"Input Directory\"\n",
    "mg_name = []\n",
    "VBmax = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    img_name.append(filename) \n",
    "    img = cv2.imread(os.path.join(directory,filename), cv2.IMREAD_GRAYSCALE)\n",
    "    ret,thresh = cv2.threshold(img,127,255,0)\n",
    "    contours,hierarchy = cv2.findContours(thresh, 1, 2)\n",
    "    result = find_contour_indices(contours)\n",
    "    print(result)\n",
    "    min_max_list = []\n",
    "    \n",
    "    for i in result:\n",
    "        CNT = contours[i]\n",
    "        #print(CNT)\n",
    "        M = cv2.moments(CNT)\n",
    "        print( M )\n",
    "        RECT = cv2.minAreaRect(CNT)\n",
    "        BOX = cv2.boxPoints(RECT)\n",
    "        BOX = np.int0(BOX)\n",
    "        FIT = cv2.drawContours(np.copy(img),[BOX],0,(255,255,255),1)\n",
    "        output_path_fit = os.path.join(directory, f\"{filename[:-4]}_%i_fit.png\"%i)\n",
    "        cv2.imwrite(output_path_fit, FIT)\n",
    "        coordinates = BOX.reshape((-1, 1, 2))\n",
    "\n",
    "        # Create a mask image with the same dimensions as the original image\n",
    "        mask = np.zeros_like(img)\n",
    "\n",
    "        # Draw a filled polygon (ROI) on the mask using the defined coordinates\n",
    "        mask = cv2.fillPoly(mask, [coordinates], (255, 255, 255))\n",
    "\n",
    "        # Perform a bitwise AND operation between the original image and the mask to extract the ROI\n",
    "        roi = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "        edges = cv2.Canny(roi,180,500)\n",
    "        output_path_canny = os.path.join(directory, f\"{filename[:-4]}_%i_fit_canny.png\"%i)\n",
    "        cv2.imwrite(output_path_canny, edges) \n",
    "        White_Pixels = np.argwhere(edges == 255)\n",
    "        White_Pixels_tolist = White_Pixels.tolist()\n",
    "        print(White_Pixels_tolist)\n",
    "        \n",
    "        for y, x in White_Pixels_tolist:\n",
    "            found = False\n",
    "            for entry in min_max_list:\n",
    "                if entry[0] == y:\n",
    "                    # Update min and max x values if necessary\n",
    "                    entry[1] = min(entry[1], x)  # min_x\n",
    "                    entry[2] = max(entry[2], x)  # max_x\n",
    "                    found = True\n",
    "                    break\n",
    "\n",
    "            if not found:\n",
    "                # If y is not already in the list, append a new entry\n",
    "                min_max_list.append([y, x, x, 0])  # [y, min_x, max_x, difference]\n",
    "\n",
    "        # Calculate the difference and update the min_max_list\n",
    "        for entry in min_max_list:\n",
    "            entry[3] = round(np.cross(BOX[1]-BOX[0],np.array([entry[2],entry[0]])-BOX[0])/np.linalg.norm(BOX[1]-BOX[0]),2)\n",
    "\n",
    "        # Print the result\n",
    "        for entry in min_max_list:\n",
    "            y, min_x, max_x, difference = entry\n",
    "            #print(f\"For y = {y}, min_x = {min_x}, max_x = {max_x}, difference = {difference}\")\n",
    "            \n",
    "        Dis = [sublist[3] for sublist in min_max_list]\n",
    "        VBmax.append(round(float(max(Dis))*1.725,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3. VB Curve\n",
    "\n",
    "After extracting the maximum thickness of the wear in each image, as already mentioned, the images are for 4 cutting edges, each after 10 cuts. You can plot the VB curve for each cutting edge. \n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/image-22.png\" alt=\"Alt text\" style=\"display: block; margin: 0 auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TASK: plot the VB curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name_new = []\n",
    "VBmax_new = []\n",
    "for i in range(0, len(img_name), 4):\n",
    "    img_name_new.append(img_name[i:i+4])\n",
    "    VBmax_new.append(VBmax[i:i+4])\n",
    "\n",
    "WB = Workbook() \n",
    "Sheet1 = WB.add_sheet ('Pixel') \n",
    "style = xlwt.XFStyle ()   # create a style Object initialization pattern  \n",
    "Al = xlwt.Alignment ()  \n",
    "Al.horz = 0x02       # arranged horizontally centered  \n",
    "style.alignment = Al  \n",
    "\n",
    "\n",
    "Sheet1.write (0,0,'Tooth',style) \n",
    "Sheet1.write (1,0,'1st Tooth',style) \n",
    "Sheet1.write (2,0,'2nd Tooth',style) \n",
    "Sheet1.write (3,0,'3rd Tooth',style) \n",
    "Sheet1.write (4,0,'4th Tooth',style) \n",
    "\n",
    "\n",
    "for i in range(len(VBmax_new)): \n",
    "\n",
    "    Sheet1.write (0,i+1,str(i+1) +'_Track',style) \n",
    "    Sheet1.write (1,i+1,float(VBmax_new[i][0]),style)\n",
    "    Sheet1.write (2,i+1,float(VBmax_new[i][1]),style)\n",
    "    Sheet1.write (3,i+1,float(VBmax_new[i][2]),style)\n",
    "    Sheet1.write (4,i+1,float(VBmax_new[i][3]),style) \n",
    "\n",
    "WB.save (r\"Output Directory\") \n",
    "\n",
    "# Extracting the tooth numbers\n",
    "tooth_numbers = [f'{i}th Tooth' for i in range(1, len(VBmax_new) + 1)]\n",
    "\n",
    "# Creating x-axis labels for all 5 cuts\n",
    "x_labels = [f'{i}' for i in range(1, 970,5)]\n",
    "\n",
    "# Transposing VBmax_new for easy plotting\n",
    "vb_values_transposed = list(map(list, zip(*VBmax_new)))\n",
    "\n",
    "# Polynomial degree\n",
    "deg = 3  # You can adjust the degree as needed\n",
    "\n",
    "# Define marker colors\n",
    "marker_colors = ['red', 'green', 'blue', 'orange']\n",
    "\n",
    "# Plotting all 5 cuts for each tooth\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, (vb_values, color) in enumerate(zip(vb_values_transposed, marker_colors)):\n",
    "    # Plot only the markers (dots) for data points\n",
    "    plt.plot(x_labels, vb_values, marker='o', linestyle='', label=f'{tooth_numbers[i]} - Data', color=color)\n",
    "    # Fit a polynomial of specified degree to the data\n",
    "    coefficients = np.polyfit(range(len(vb_values)), vb_values, deg)\n",
    "    polynomial = np.poly1d(coefficients)\n",
    "    # Plot the best-fit polynomial line\n",
    "    #plt.plot(x_labels, polynomial(range(len(vb_values))), marker='', linestyle='--', label=f'{tooth_numbers[i]} - Best Fit', color=color)\n",
    "\n",
    "plt.xlabel('Cut', fontsize=18)\n",
    "plt.ylabel('VB (Î¼m)', fontsize=18)\n",
    "plt.title('VB Values for all 685 Cuts')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tick_params(axis='y', which='major', labelsize=15)\n",
    "plt.tick_params(axis='x', which='major', labelsize=15)\n",
    "\n",
    "# Reduce the number of x-axis labels by selecting a subset\n",
    "plt.xticks(ticks=range(0, len(x_labels), 10), labels=[x_labels[i] for i in range(0, len(x_labels), 10)], rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "# Save the plot as an image (optional)\n",
    "plt.savefig(r\"Output Directory\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/image-24.png\" alt=\"Alt text\" style=\"display: block; margin: 0 auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2.4. Data Filtering (Extra Point)\n",
    "\n",
    "If you have already finished up to this section, then you are officially done. Congratulations! ðŸ˜‰\n",
    "\n",
    "However, if you are interested in doing an extra task, please go ahead.\n",
    "\n",
    "After plotting the VB curve, you might notice that some results do not follow the trend and are outliers. The most obvious ones are those that are higher than the previous and the next points, which is not possible. So, try to filter the data and eliminate the artifact results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TASK: Implement a clustering method for data filtering and eliminate the outliers"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
